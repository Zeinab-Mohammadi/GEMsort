{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing multielectrode GEMsort algorithm by using 16-channel synthesized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import apply_along_axis as apply\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy import signal\n",
    "from GEMsort_func import GEMsort\n",
    "from Smoothing_data import Smoothing_filter\n",
    "from Cut_func import cut\n",
    "from scipy.signal import butter, lfilter\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import svd\n",
    "from numpy.linalg import svd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import struct\n",
    "import time\n",
    "import numpy.matlib\n",
    "import numpy.matlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose one of the datasets in the below cell (generated by the data file in this package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and plotting the data\n",
    "np.random.seed(10)\n",
    "path = '../../data/Multi_16channels/'\n",
    "\n",
    "# data=np.load(path + '/multi_16ch_usualdata.npy', allow_pickle=True)\n",
    "data = np.load(path + '/multi_16ch_samecells.npy', allow_pickle=True) #this is the similar cells (for two cells)  dataset\n",
    "# data=np.load(path + '/multi_16ch_sametime.npy', allow_pickle=True) #this is the same firing time (for two cells) dataset\n",
    "\n",
    "X = data\n",
    "\n",
    "%matplotlib inline\n",
    "for i in range(16):\n",
    "    plt.plot(X[i,:][0:10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are running the data for same time firing cells or similar cells of channels i, j (i.e., multi_16ch_sametime or multi_16ch_samecells), uncomment below cell to see the same time effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ for multi_16ch_sametime data or multi_16ch_samecells ############\n",
    "# i = 0\n",
    "# j = 3\n",
    "# # Size = 10000 #if data is multi_16ch_sametime \n",
    "# Size = 1000 #if data is multi_16ch_samecells   \n",
    "\n",
    "\n",
    "# plt.plot(X[i,:][0:Size], c='r')\n",
    "# plt.plot(X[j,:][0:Size], c= 'b')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing filter\n",
    "#%matplotlib qt\n",
    "\n",
    "for i in range(16):\n",
    "    data_raw = X[i, :]\n",
    "    plt.plot(data_raw)\n",
    "    filtered_data = Smoothing_filter(data_raw, low=10, high=5000, sf=80000, order=2)\n",
    "    plt.plot(filtered_data, c='r')\n",
    "#     plt.show()\n",
    "    \n",
    "    X[i, :] = filtered_data\n",
    "\n",
    "# plt.plot(data_raw[1:L,:])\n",
    "# plt.plot(filtered_data[1:L,:],c='r')\n",
    "# plt.show()\n",
    "\n",
    "#short view\n",
    "# for i in range(16):\n",
    "#     plt.plot(X[i, :])\n",
    "# plt.xlim([0, 10000])\n",
    "# plt.ylim([-0.3, 0.3])\n",
    "# plt.show()\n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "# for i in range(16):\n",
    "#     y = np.zeros((1, 1000)) + i + 5\n",
    "#     plt.plot(X[i, :][0: 1000] + i) # +i is only for plotting figures with verrtical distace in one fig\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap \n",
    "np.random.seed(0)\n",
    "sns.set_theme()\n",
    "uniform_data = X[:, 0:2000]\n",
    "# ax = sns.heatmap(uniform_data, cmap=\"YlGnBu\", xticklabels=False)#, vmin=0.2, vmax=1) #cmap=\"Greens\",\"BuPu\",\"Blues\"\n",
    "# ax = sns.heatmap(uniform_data, cmap=\"YlGnBu\", xticklabels=False, center=0)#, vmin=0.2, vmax=1)\n",
    "\n",
    "uniform_data = X[:, 0:1000]\n",
    "ax = sns.heatmap(uniform_data, cmap=\"YlGnBu\", xticklabels=False)#, vmin=0.2, vmax=1)\n",
    "# ax = sns.heatmap(uniform_data, cmap=\"YlGnBu\", xticklabels=False, center=0)#, vmin=0.2, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### main program for getting spikes of channels #####\n",
    "start_time = time.time()\n",
    "\n",
    "#stage 1: detecting peaks of all channels\n",
    "T1 = 64\n",
    "ch_num = 16\n",
    "T = X.shape[1] #length of data\n",
    "N = T\n",
    "Tdis = 50\n",
    "\n",
    "p_all = np.array([], dtype = object).reshape((1,0))\n",
    "cut_ch = []\n",
    "\n",
    "for k in range (ch_num): \n",
    "    cut_ch .append([])\n",
    "\n",
    "for i in range (16): #for every channel\n",
    "    #print(i)\n",
    "    x = X[i,:] \n",
    "    sigma = np.median(np.abs(x) / 0.6745)\n",
    "    Tp = 4 * sigma  \n",
    "    p,_ = scipy.signal.find_peaks(x, height = Tp, distance = Tdis) #np.abs(x) \n",
    "    \n",
    "    if i == 15:\n",
    "        p,_ = scipy.signal.find_peaks(np.abs(x), height = Tp, distance = Tdis)\n",
    "        \n",
    "    for j in range(np.array(p).shape[0]):\n",
    "         cut_ch[i].append(cut(x,p[j],T1)[0]) \n",
    "    \n",
    "    if p == []:\n",
    "        p = [0] #to prevent error, so in every row if p=0 means: no peak in that channel\n",
    "    y_arr = np.array([], dtype = np.int32)\n",
    "    y = p\n",
    "    y_arr = np.append(y_arr,y)\n",
    "    #print(y_arr)\n",
    "    p_all = np.append(p_all, 0)\n",
    "    #print(p_all)\n",
    "    p_all[-1] = y_arr.astype(int) \n",
    " \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# for i in range(np.array(cut_ch).shape[1]):\n",
    "#     plt.plot(np.array(cut_ch)[0, i, :])\n",
    "# plt.show()       \n",
    "\n",
    "# for i in range(np.array(cut_ch).shape[1]):\n",
    "#     plt.plot(np.array(cut_ch)[0, i, :])\n",
    "#     plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster plot for cells' spikes\n",
    "%matplotlib qt\n",
    "path = '/.../results'\n",
    "colors = ['dodgerblue', 'skyblue', 'gray','deeppink','orange','saddlebrown','lawngreen', 'g','black','cyan','red','brown','lightgray','yellow','pink','magenta']\n",
    "main_cells_channels = [0, 3, 5, 7, 9, 11, 13, 15]\n",
    "cells = range(1, 9)\n",
    "length_signal = 20000 \n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "print('p_all[i][0:length_signal].shape = ', p_all[i][0:length_signal].shape)\n",
    "print('x.shape=', x.shape)\n",
    "xticks = [0, 50, 100, 150, 200, 250, 300, 350, 400]\n",
    "k = 0\n",
    "for i in main_cells_channels:\n",
    "    k = k+1\n",
    "    x = np.zeros((1, p_all[i].shape[0])) + k\n",
    "    ax.scatter(p_all[i], x, color=colors[i], marker='|', linewidth=0.6)\n",
    "    ax.set(xticklabels=xticks)\n",
    "\n",
    "plt.title('Spike raster plot', fontsize=10)\n",
    "plt.ylabel('Neuron', fontsize=10)\n",
    "plt.yticks( cells, fontsize=10)\n",
    "plt.xlabel('Time (msec)', fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.xlim(0, length_signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = np.hstack(p_all) #put all 16 channels in a row for comparing all times \n",
    "rowp = a[None, :]\n",
    "\n",
    "channels = []\n",
    "times = []\n",
    "\n",
    "#finding the similar peaks in near times and channels\n",
    "for k in range (np.array(rowp).shape[1]): \n",
    "    channels.append([]) \n",
    "    times.append([])\n",
    "        \n",
    "for k in range (np.array(rowp).shape[1]): #for every peak  \n",
    "    for i in range (p_all.shape[0]): #number of channels \n",
    "        for j in range (p_all[i].shape[0]):\n",
    "            if all ([p_all[i][j] != 0 and np.abs(p_all[i][j] - rowp[0,k]) < 2 and X[i,rowp[0,k]] != 0]): \n",
    "#                 print(p_all[i][j])\n",
    "#                 print(rowp[0,k])\n",
    "                channels[k].append(i) #all the channels number with the same peak(k)\n",
    "                times[k].append(j) #time values for that channel\n",
    "                \n",
    "# rowtt = np.unique(rowf)\n",
    "# for i in range(rowtt.shape[0]):\n",
    "#     if np.array(rowtt[i]).shape[0] == 1:\n",
    "#         print(i)\n",
    "#         channels[1,i] = -1\n",
    "        \n",
    "#old_sig = np.copy(signals) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlations of all spikes happening in near times  \n",
    "#Determining the channel with maximum correlation for the next part\n",
    "%matplotlib inline\n",
    "\n",
    "start_time = time.time()\n",
    "signals_after_corr = deepcopy(cut_ch) \n",
    "\n",
    "th_cor = 0.5\n",
    "maxx = np.zeros((1,np.array(rowp).shape[1]))\n",
    "zeross = 0 #this is the total number of peaks that will set to zero\n",
    "#for k in range (np.array(rowp).shape[1]): \n",
    "for k in range(np.array(rowp).shape[1]): #the peak counter    \n",
    "    #print rowp[0][k] \n",
    "    #print(k)\n",
    "\n",
    "    if all ([channels[k] != [] and np.array(channels[k]).shape[0] != 1]) : \n",
    "        #repetitive elements of rows since they have different rowp (peak time)\n",
    "        #print(channels[k])\n",
    "        maxx[0,k] = -999999\n",
    "        #print(k)\n",
    "        for p in range (np.array(channels[k])[:, None].shape[0]) : #considering number of same peaks in every group           \n",
    "            #print p\n",
    "            for t in range (np.array(channels[k])[:, None].shape[0]):\n",
    "#                 print(t)\n",
    "#                 print(p)\n",
    "\n",
    "#below condition checks that channels be near each other (less than 3)             \n",
    "                if all ([channels[k][p] != channels[k][t] and np.abs(channels[k][p]-channels[k][t]) < 3 and np.any(signals_after_corr[channels[k][p]][times[k][p]]) != 0 and np.any(signals_after_corr[channels[k][t]][times[k][t]]) != 0]):                 \n",
    "                    #print(channels[k][p])\n",
    "                    #print(channels[k][t])\n",
    "                    corr = np.corrcoef(signals_after_corr[channels[k][p]][times[k][p]], signals_after_corr[channels[k][t]][times[k][t]])[0, 1]\n",
    "                    #corr = np.correlate(cut_ch[channels[k][p]][k], cut_ch[channels[k][t]][k])\n",
    "                    #plt.plot(signals_after_corr[channels[k][p]][times[k][p]],'r')\n",
    "                    #plt.plot(signals_after_corr[channels[k][t]][times[k][t]])\n",
    "                    plt.show()\n",
    "                    print(corr)\n",
    "                    if corr >= th_cor:  #if correlation is more than the threshold\n",
    "#                         print('rowp=', channels[k][p])\n",
    "#                         print('rowt=', channels[k][t])\n",
    "                        if np.abs(X[channels[k][p],rowp[0, k]]) >= maxx[0, k]:\n",
    "                            maxx[0, k] = np.abs(X[channels[k][p],rowp[0, k]])\n",
    "                            #print(maxx[0,k])\n",
    "                        else:    \n",
    "                            signals_after_corr[channels[k][p]][times[k][p]] = np.zeros((1, T1)) #if that signal is not the max for correlation remove it \n",
    "                            zeross = zeross + 1\n",
    "                            #print('rowp', channels[k][p]) #number of channel which is removed\n",
    "                        if np.abs(X[channels[k][t],rowp[0, k]]) > maxx[0, k]: #X[...] is the amount of cut_ch (spike) in peak k\n",
    "                            maxx[0, k] = np.abs(X[channels[k][t],rowp[0, k]])\n",
    "                            signals_after_corr[channels[k][p]][times[k][p]] = np.zeros((1, T1))\n",
    "                            #print('rowp', channels[k][p])\n",
    "                            #print(maxx[0,k])\n",
    "                            zeross = zeross + 1\n",
    "                        else:    \n",
    "                            signals_after_corr[channels[k][t]][times[k][t]] = np.zeros((1, T1))\n",
    "                            zeross = zeross + 1\n",
    "                        #print(maxx[0,k])    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total number of spikes\n",
    "t = 0\n",
    "\n",
    "for i in range (16):\n",
    "    for k in range (np.array(signals_after_corr[i]).shape[0]): #for every peak\n",
    "        if np.any(np.array(signals_after_corr[i])[k]) != 0:\n",
    "            plt.plot(np.array(signals_after_corr[i])[k])\n",
    "            t = t+1\n",
    "    print(i+1)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =['dodgerblue', 'skyblue', 'gray','deeppink','orange','saddlebrown','lawngreen', 'g','black','cyan','red','brown','lightgray','yellow','pink','magenta']\n",
    "col = colors[7]\n",
    "\n",
    "#plt.plot(np.array(cluster[3])[:, 0],np.array(cluster[3])[:, 1], col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.array(signals_after_corr).shape[0]):\n",
    "    final_spikes = []\n",
    "    for j in range(np.array(signals_after_corr[i]).shape[0]):\n",
    "        if np.all(signals_after_corr[i][j] == 0): \n",
    "            True_sig = 1  #print(cut_ch[i][j])\n",
    "        else:\n",
    "            final_spikes.append(signals_after_corr[i][j])\n",
    "    if final_spikes != []:        \n",
    "        print(i + 1) #this would be the channel number\n",
    "        res = np.array(final_spikes)       \n",
    "        varcovmat = np.cov(res.T)\n",
    "        k = np.array(np.mean(res.T,1))\n",
    "        tt = []\n",
    "        for s in range(res.shape[0]):\n",
    "            tt.append(k)\n",
    "        varcovmat = res.T - np.array(tt).T\n",
    "\n",
    "        u, s, v = svd(varcovmat)\n",
    "        pca_data = np.dot(res,u[:,0:2])\n",
    "        pca_data.shape\n",
    "\n",
    "#         plt.scatter(pca_data[:,0],pca_data[:,1],c=colors[i])\n",
    "\n",
    "#         #plt.xlim([-400,400])\n",
    "#         #plt.ylim([-300,300])\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting PCA of the data\n",
    "\n",
    "num = t #this is calculated in the previous cell, giving the number of non-zero signals    \n",
    "res = np.zeros((num, T1)) #put non-zero elements in res as arrays\n",
    "chnum = np.zeros((num, 1)) #contains the channel number label for colors in plotting \n",
    "\n",
    "#for determining the labels and groups of clusters\n",
    "\n",
    "clus_spike = []\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "clus_spike.append([])\n",
    "\n",
    "p = 0\n",
    "for i in range (16):\n",
    "    for j in range (np.array(signals_after_corr[i]).shape[0]):\n",
    "        if (np.any(np.array(signals_after_corr[i])[j]) != 0): #measures the number of non zero elements (3d axis)\n",
    "#             while p < np.array(signals_after_corr[i])[j].shape[0]:\n",
    "            res[p,:] = np.array(signals_after_corr[i])[j]\n",
    "            chnum[p,0] = i\n",
    "            data_ch = [i] #these are the 64 signals \n",
    "            p = p + 1\n",
    "            if i == 0:\n",
    "                clus_spike[0].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 1:\n",
    "                clus_spike[1].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 2:\n",
    "                clus_spike[2].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 3:\n",
    "                clus_spike[3].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 4:\n",
    "                clus_spike[4].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 5:\n",
    "                clus_spike[5].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 6:\n",
    "                clus_spike[6].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 7:\n",
    "                clus_spike[7].append(np.array(signals_after_corr[i])[j]) \n",
    "            if i == 8:\n",
    "                clus_spike[8].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 9:\n",
    "                clus_spike[9].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 10:\n",
    "                clus_spike[10].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 11:\n",
    "                clus_spike[11].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 12:\n",
    "                clus_spike[12].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 13:\n",
    "                clus_spike[13].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 14:\n",
    "                clus_spike[14].append(np.array(signals_after_corr[i])[j])\n",
    "            if i == 15:\n",
    "                clus_spike[15].append(np.array(signals_after_corr[i])[j])\n",
    "          \n",
    "            \n",
    "#np.save('clus_spike', clus_spike)            \n",
    "\n",
    "varcovmat = np.cov(res.T)\n",
    "k = np.array(np.mean(res.T,1))\n",
    "tt = []\n",
    "for i in range(res.shape[0]):\n",
    "   tt.append(k)\n",
    "varcovmat = res.T - np.array(tt).T\n",
    "\n",
    "u, s, v = svd(varcovmat)\n",
    "pca_data = np.dot(res,u[:,0:2])\n",
    "pca_data.shape\n",
    "\n",
    "for i in range(chnum.shape[0]):    \n",
    "    plt.scatter(pca_data[i,0],pca_data[i,1], c=colors[int(chnum[i,0])])\n",
    "                \n",
    "#plt.xlim([-400,400])\n",
    "#plt.ylim([-300,300])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GEMsort to cluster the data\n",
    "\n",
    "%matplotlib qt \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "T_cluster = 50 # threshold for the number of spikes to be considered as a cluster\n",
    "\n",
    "ch_num = 16\n",
    "for s in range(ch_num):\n",
    "#     print('s=',s)\n",
    "    ch_pca = []\n",
    "\n",
    "    for i in range(pca_data.shape[0]): \n",
    "        #print(int(chnum[i,0]))\n",
    "        if s == int(chnum[i,0]):\n",
    "            ch_pca.append(list(pca_data[i,:]))\n",
    "    ch_pca = np.array(ch_pca)  \n",
    "    if ch_pca.shape[0] > T_cluster: #if there is data\n",
    "        ax.plot(ch_pca[:,0], ch_pca[:,1], s+1, linestyle=\"none\", marker=\"o\", markersize=3, color=colors[int(s)],zorder=1)#c=colors[int(s)],zorder=1)     \n",
    "        ax.set_zlim(np.array([0,32])*0.5)\n",
    "    if ch_pca.shape[0] > T_cluster:\n",
    "        prenumnode = 7 \n",
    "        GEMsort_dataset = ch_pca\n",
    "        Nodes,GEMsort_C,GEMsort_w, nodes_total,prenumnode,d,nodess = GEMsort(prenumnode, GEMsort_dataset)\n",
    "        \n",
    "        for i in range(GEMsort_C.shape[0]):\n",
    "            for j in range (GEMsort_C.shape[0]):\n",
    "                if GEMsort_C[i,j] != -1:\n",
    "                   # print i,j\n",
    "                    x = [GEMsort_w[i,0],GEMsort_w[j,0]]\n",
    "                    y = [GEMsort_w[i, 1], GEMsort_w[j, 1]]\n",
    "                    ax.scatter(x, y, s+1, s=100, c ='r', zorder=3)\n",
    "                    ax.plot(x, y, s+1,'k', zorder=2, lw=2) \n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=15, rotation=0)\n",
    "ax.set_ylabel('PC2', fontsize=15)\n",
    "ax.set_zlabel('Channel Number', fontsize=15, rotation=60)\n",
    "\n",
    "ax.set_zticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
    "#ax.set_xlim(left, right)\n",
    "#ax.set_ylim(-0.1, 0.4)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
