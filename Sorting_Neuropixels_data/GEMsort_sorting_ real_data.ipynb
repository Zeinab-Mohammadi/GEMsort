{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter,lfilter\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from matplotlib.pyplot import mlab\n",
    "from GEMsortfunc_for_multi import GEMsort\n",
    "from data_func import get_chunk, cut\n",
    "from numpy import apply_along_axis as apply\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy import signal\n",
    "from functools import reduce\n",
    "from numpy.linalg import svd\n",
    "from numpy import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "\n",
    "import numpy.matlib\n",
    "import scipy, os\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree\n",
    "import pandas as pd\n",
    "import struct\n",
    "import copy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = np.memmap('/.../data/experiment1_101-1_0.dat', dtype=np.int16,mode='r')\n",
    "\n",
    "channels = 384\n",
    "start = 0\n",
    "end = 60\n",
    "sampling_rate = 30000\n",
    "T0 = 0\n",
    "data = get_chunk(mm,start,end,channels,sampling_rate)\n",
    "\n",
    "# sf = 30000 #sampling frequency\n",
    "# T = data.shape[1] \n",
    "# dur_sec = T/sf \n",
    "# dur_min = dur_sec/60\n",
    "# print(dur_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#common average referencing and filtering\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ch_num \u001b[38;5;241m=\u001b[39m channels\n\u001b[0;32m----> 4\u001b[0m med \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(data[:,T0:\u001b[43mT\u001b[49m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m data_newm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m384\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "#common average referencing and filtering\n",
    "\n",
    "ch_num = channels\n",
    "med = np.median(data[:,T0:T],axis=0)\n",
    "data_newm = np.zeros((data.shape[0],data.shape[1])) \n",
    "\n",
    "for i in range(384):\n",
    "     data_newm[i,T0:T] = data[i,T0:T] - med\n",
    "\n",
    "data_raw2 = copy.deepcopy(data_newm) \n",
    "\n",
    "for i in range(ch_num):\n",
    "    #print(i)\n",
    "    #i=ID_channels[0]\n",
    "    data_raw = copy.deepcopy(data_raw2[i,:])\n",
    "\n",
    "    def filter_data(data_raw, low, high, sf, order=2):\n",
    "        nyq = sf/2\n",
    "        low = low/nyq\n",
    "        high = high/nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        filtered_data = lfilter(b, a, data_raw)\n",
    "        return filtered_data\n",
    "\n",
    "    L = data.shape[1] #length of the data\n",
    "    sf = 10000 \n",
    "    filtered_data = filter_data(data_raw, low=100, high=800, sf=sf)\n",
    "\n",
    "    data_newm[i,:] = filtered_data\n",
    "\n",
    "data_new2 = data_newm        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### plot Neuropixels data heatmap #######\n",
    "%matplotlib qt\n",
    "npix_p3_reference_channels = np.array([36, 75, 112, 151, 188, 227, 264, 303, 340, 379])\n",
    "ch_ref = npix_p3_reference_channels \n",
    "data_newm_good_channels= copy.deepcopy(data_newm)\n",
    "\n",
    "for i, ch in enumerate(ch_ref):\n",
    "    data_newm_good_channels [ch,:]= copy.deepcopy(data_newm[ch+1,:])\n",
    "    \n",
    "uniform_data = data_newm_good_channels[:, 352000:354000] #352000:354000\n",
    "fig = plt.figure(figsize=(2*8, 20), dpi=150, facecolor='w', edgecolor='k')\n",
    "# ax = sns.heatmap(uniform_data, cmap=\"rainbow\", xticklabels=False, cbar=True)#, vmin=0.2, vmax=1)\n",
    "ax = sns.heatmap(uniform_data, center=0, xticklabels=False, cbar=True)#, vmin=0.2, vmax=1)\n",
    "\n",
    "plt.title('Neuropixels recording sample', fontsize=10)\n",
    "plt.xlabel('Time (s)', fontsize=10)\n",
    "plt.ylabel('Channel number', fontsize=10)\n",
    "# plt.savefig(path + 'Neuropixels heatmap.png', dpi=300, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Plot recordings of several channels together ####### \n",
    "%matplotlib qt\n",
    "a = 120\n",
    "b = 140\n",
    "c = 352000\n",
    "d = 352000 + 400\n",
    "N = b - a #number of row windows\n",
    "x = range(251000, 253000, 1)\n",
    "# ymax=np.max(data_newm[145,:])\n",
    "# ymin= np.min(data_newm[145,:])\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(N, hspace=0)\n",
    "axs = gs.subplots(sharex=True, sharey=True)\n",
    "fig.suptitle('Nearby channels signals', fontsize=20)\n",
    "plt.xlabel('Time (s)', fontsize=20)\n",
    "# plt.ylabel('Channel number', fontsize=20)\n",
    "\n",
    "for i in range(a, b):\n",
    "    y1 = data_newm[i, c:d]\n",
    "    i2 = i - a\n",
    "    axs[i2].plot(y1)\n",
    "    axs[i2].set(xticklabels=[])\n",
    "    axs[i2].set(yticklabels=[])\n",
    "\n",
    "# Duration of the plot     \n",
    "dur_sec_diff = abs(d - c) / sf \n",
    "# dur_min1=dur_sec1/60\n",
    "print(dur_sec_diff)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### the main program for extracting the spikes of channels #######\n",
    "\n",
    "Tdis = 150\n",
    "start_time = time.time()\n",
    "T1 = 82 \n",
    "coef = 4.2\n",
    "\n",
    "#sig64=np.zeros((X.shape[0],T1))\n",
    "#p_all=np.zeros((X.shape[0],N)) \n",
    "\n",
    "X = data_new2 #just for one channel \n",
    "X[:,0:T0] = 0\n",
    "GEMsort_all_times = []\n",
    "\n",
    "for k in range (ch_num): \n",
    "    GEMsort_all_times .append([])\n",
    "\n",
    "p_all = np.array([], dtype=object).reshape((1,0))\n",
    "cut_ch = []\n",
    "\n",
    "for k in range (ch_num):\n",
    "    cut_ch .append([])\n",
    "\n",
    "for i in range (ch_num):\n",
    "    #print(i)\n",
    "    x = X[i,:] \n",
    "    sigma = np.median(np.abs(x) / 0.6745)\n",
    "    Tp = coef * sigma \n",
    "    p,_ = scipy.signal.find_peaks(np.abs(x), height=Tp, distance=Tdis) #peak(x,Tp,Tdis) #this function gives the places(times) that peaks occure\n",
    "    GEMsort_all_times[i].append(p.astype('int')[:])\n",
    "    #print(GEMsort_all_times[i])\n",
    "    \n",
    "    for j in range(np.array(p).shape[0]):\n",
    "         cut_ch[i].append(cut(x,p[j],T1)[0]) \n",
    "\n",
    "    if p == []:\n",
    "        p = [0] \n",
    "    y_arr = np.array([], dtype=np.int32)\n",
    "    y = p\n",
    "    y_arr = np.append(y_arr,y)\n",
    "    p_all = np.append(p_all, 0)\n",
    "    p_all[-1] = y_arr.astype(int) \n",
    " \n",
    "\n",
    "#print(p_all)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for i in range(ch_num):\n",
    "    GEMsort_all_times[i] = np.array(GEMsort_all_times[i])[0]#just to have correct dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Data reduction #######\n",
    "\n",
    "start_time = time.time()\n",
    "N = 5\n",
    "ch_num = 384\n",
    "all_ind_i = []\n",
    "all_ind_j = []\n",
    "xy = p_all[0]\n",
    "cor_thr =  0.8\n",
    "\n",
    "for s in range(round(ch_num/N)):\n",
    "#     print('s =',s)\n",
    "    s1 = s*N\n",
    "    s2 = s1+N\n",
    "    if s2 >= ch_num:\n",
    "        s2 = ch_num-1\n",
    "#     a = np.hstack(p_all[s1:s2]) \n",
    "#     rowp = a[None,:]\n",
    "    #for k in range (np.array(rowp).shape[1]):\n",
    "    xy = p_all[s1]\n",
    "\n",
    "    for i in range (s1 + 1, s2 + 1): \n",
    "#         print('i=',i)\n",
    "#         for j in range(i+1,s2):\n",
    "#             print('j=',j)\n",
    "        xy = np.intersect1d(p_all[i], xy)\n",
    "    \n",
    "    for j in range(N - 1):\n",
    "        if (s1 + j + 1) < ch_num:\n",
    "            for t in range(xy.shape[0]): \n",
    "                #print('s1+j+1=',s1+j+1)\n",
    "                x_ind = np.where(xy[t] == p_all[s1])[0][0]\n",
    "                y_ind = np.where(xy[t] == p_all[s1+j+1])[0][0]\n",
    "                conf = scipy.stats.pearsonr(np.array(cut_ch)[s1][x_ind], np.array(cut_ch)[s1+j+1][y_ind])[0]\n",
    "\n",
    "                if conf > cor_thr:\n",
    "                    if np.max(np.array(cut_ch)[s1][x_ind]) > np.max(np.array(cut_ch)[s1+j+1][y_ind]):\n",
    "                        all_ind_j.append(y_ind) \n",
    "\n",
    "            cut_ch[s1+j+1] = np.delete(cut_ch[s1+j+1], all_ind_j,0)\n",
    "            p_all[s1+j+1] = np.delete(p_all[s1+j+1], all_ind_j,0) \n",
    "            all_ind_j=[]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the detected spikes using GEMsort without data reduction (to know the number of spikes in each group)\n",
    "\n",
    "channels_num = ch_num\n",
    "GEMsort_cluster = []\n",
    "#GEMsort_cluster_number=[]\n",
    "GEMsort_clusters_times = []\n",
    "\n",
    "for i in range(channels_num): \n",
    "    GEMsort_cluster.append([])\n",
    "    #GEMsort_cluster_number.append([])\n",
    "    GEMsort_clusters_times.append([])\n",
    "    \n",
    "GEMsort_ave_cluster = []\n",
    "for i in range(channels_num): \n",
    "    GEMsort_ave_cluster.append([])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "ch0 = 0 \n",
    "channels_num = 384\n",
    "\n",
    "for ch in range(ch0, channels_num): #for every channel \n",
    "    if ch not in ch_ref:\n",
    "#     print(ch)\n",
    "        res = np.array((cut_ch)[ch])   \n",
    "        varcovmat = np.cov(res.T)\n",
    "        k = np.array(np.mean(res.T, 1))\n",
    "        tt = []\n",
    "        for s in range(res.shape[0]):\n",
    "            tt.append(k)\n",
    "        varcovmat = res.T - np.array(tt).T\n",
    "\n",
    "        u, s, v = svd(varcovmat)\n",
    "        pca_data = np.dot(res,u[:, 0:2])\n",
    "\n",
    "        GNG_dataset = (pca_data / 500.)\n",
    "        prenumnode = round(pca_data.shape[0] / 50)  \n",
    "        prenumnode_main = prenumnode\n",
    "        GNG_eb = 0.9  # Learning rate of the winning node S \n",
    "        GNG_en = 0.0001  # Learning rate of the direct topological neighbors of S \n",
    "        GNG_edgethred = 10\n",
    "        GNG_beta = 0.001\n",
    "        GNG_alpha = 0.5\n",
    "        Nodes,GNG_C,GNG_w, nodes_total,prenumnode,d,nodess = GEMsort(prenumnode, GNG_dataset,GNG_eb,GNG_en,GNG_edgethred,GNG_beta,GNG_alpha)\n",
    "\n",
    "        #determinig number of groups\n",
    "        all_nodes = []\n",
    "        set1 = []\n",
    "        set2 = []\n",
    "        if np.array(Nodes).shape[0] != 0:\n",
    "            for i in range(prenumnode):\n",
    "                for j in range(prenumnode):\n",
    "                    if GNG_C[i, j] != -1.:\n",
    "                        set1.append(i)\n",
    "                        set2.append(j)\n",
    "            d = np.zeros((np.array(set1).shape[0], 2))\n",
    "            d[:, 0] = set1\n",
    "            d[:, 1] = set2\n",
    "            for k in range(prenumnode):\n",
    "                nodes = []\n",
    "                for i in range(d.shape[0]):\n",
    "                    nodes.append(k)\n",
    "                    if d[i, 0] == k:\n",
    "                        nodes.append(d[i, 1])\n",
    "                    # print nodes\n",
    "                for i in range(d.shape[0]):\n",
    "                    for j in nodes:\n",
    "                        if d[i, 0] == j:\n",
    "                            nodes.append(d[i, 1])\n",
    "                for i in range(d.shape[0]):\n",
    "                    if d[i, 1] == k:\n",
    "                        nodes.append(d[i, 0])\n",
    "                for i in range(d.shape[0]):\n",
    "                    for j in (nodes):\n",
    "                        if d[i, 1] == j:\n",
    "                            nodes.append(d[i, 0])\n",
    "                nodes = np.unique(nodes)\n",
    "                all_nodes.append(nodes)\n",
    "\n",
    "            #identifying final groups\n",
    "            nodes_total = []\n",
    "            for k in range(prenumnode):\n",
    "                a = []\n",
    "                for j in range(prenumnode):\n",
    "                    if np.array(all_nodes)[j][-1] == k:\n",
    "                        a = np.array(all_nodes)[j]\n",
    "                if a!= []:\n",
    "                    nodes_total.append(a)\n",
    "            nodes_total \n",
    "\n",
    "            #put the clusters with common nodes in the same group\n",
    "            for i in range(np.array(nodes_total).shape[0]):\n",
    "                if i < np.array(nodes_total).shape[0]:\n",
    "                    for j in range(i): \n",
    "                        if i < np.array(nodes_total).shape[0]:\n",
    "        #                     print(np.array(nodes_total)[i])\n",
    "        #                     print(np.array(nodes_total)[j])\n",
    "                            a = np.where(np.array(nodes_total)[i] == np.array(nodes_total)[j])[0]\n",
    "                            a_set = set(np.array(nodes_total)[i]) \n",
    "                            b_set = set(np.array(nodes_total)[j]) \n",
    "\n",
    "                            if (a_set & b_set): \n",
    "                                s = np.unique(np.concatenate((np.array(nodes_total)[i],np.array(nodes_total)[j])))\n",
    "                                np.array(nodes_total)[i] = s\n",
    "                                nodes_total = np.delete(nodes_total,j,0)\n",
    "        #                         print(nodes_total)\n",
    "\n",
    "            line_nodess = np.hstack(nodes_total)\n",
    "            GNG_metric = 2.\n",
    "\n",
    "        # have the members of every cluster\n",
    "            for i in range(np.array(nodes_total).shape[0]):\n",
    "                GEMsort_cluster[ch].append([])\n",
    "                GEMsort_clusters_times[ch].append([])\n",
    "\n",
    "            for i in range(GNG_dataset.shape[0]): \n",
    "                dis = []\n",
    "                for j in range(len(line_nodess)): #number of groups           \n",
    "                        dis.append((np.linalg.norm((GNG_dataset[i] - GNG_w[int(line_nodess[j])]), GNG_metric) ** 2))\n",
    "                mindis, minarg = np.array(dis).min(), np.array(dis).argmin()\n",
    "                near_node = line_nodess[minarg]\n",
    "\n",
    "                for j in range(len(nodes_total)):\n",
    "                    for k in range(len(nodes_total[j])):\n",
    "                        if nodes_total[j][k] == line_nodess[minarg]:\n",
    "                            GEMsort_cluster[ch][j].append(res[i])    \n",
    "                            #GNG_dataset2[i,2] = j\n",
    "                            GEMsort_clusters_times[ch][j].append(GEMsort_all_times[ch][i]) \n",
    "        #                     print('ch=%d' %ch)\n",
    "        #                     print(GEMsort_clusters_times[ch][j])\n",
    "            #keep the average of clusters in a matrix\n",
    "            for i in range(np.array(GEMsort_cluster[ch]).shape[0]):\n",
    "                GEMsort_ave_cluster[ch].append([])   \n",
    "\n",
    "            for k in range(np.array(GEMsort_cluster[ch]).shape[0]): \n",
    "                GEMsort_ave_cluster[ch][k] = np.mean(GEMsort_cluster[ch][k],axis=0)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))       \n",
    "\n",
    "#plot spikes in every cluster\n",
    "# ch = 86\n",
    "# for i in range(np.array(GEMsort_cluster[ch]).shape[0]):\n",
    "#     for k in range(np.array(GEMsort_cluster[ch][i]).shape[0]):\n",
    "#          plt.plot(GEMsort_cluster[ch][i][k])\n",
    "#     plt.show() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# know the ids (numbers) for clusters: managing the ids channel by channel \n",
    "num_id = -1\n",
    "GEMsort_clust_id = []\n",
    "GEMsort_all_id_one_row = []\n",
    "for ch in range (channels_num):\n",
    "    GEMsort_clust_id.append([])\n",
    "    \n",
    "for ch in range (channels_num):\n",
    "        #print(ch)\n",
    "        for j in range((np.array(GEMsort_cluster[ch]).shape[0])):\n",
    "            #print(np.array(GEMsort_cluster[ch]).shape[0])  \n",
    "            num_id = num_id + 1\n",
    "            GEMsort_clust_id[ch].append(num_id)\n",
    "\n",
    "# copy arrays        \n",
    "GEMsort_clusters_times_original = copy.deepcopy(GEMsort_clusters_times)\n",
    "GEMsort_cluster_original = copy.deepcopy(GEMsort_cluster) #this contains spikes of channels\n",
    "GEMsort_clust_id_original = copy.deepcopy(GEMsort_clust_id)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes times detected by GEMsort\n",
    "\n",
    "GEMsort_all_times_num_GEMsort = 0\n",
    "i = 0\n",
    "for k in range(384):\n",
    "    #      if (a.shape[0]) < 1:\n",
    "    #         #print(k)\n",
    "            i = i + 1 #number of channels with spikes\n",
    "            GEMsort_all_times_num_GEMsort = GEMsort_all_times_num_GEMsort + np.array(GEMsort_all_times)[k].shape[0]\n",
    "            #print(np.array(GEMsort_all_times)[k].shape[0])\n",
    "print(GEMsort_all_times_num_GEMsort) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the number of clusters before merging\n",
    "GEMsort_all_id_one_row = []\n",
    "for ch in range(384):\n",
    "    if i not in ch_ref:\n",
    "        if np.array(GEMsort_clust_id[ch]).shape[0] > 0: \n",
    "            for idd in range(np.array(GEMsort_clust_id[ch]).shape[0]): \n",
    "                GEMsort_all_id_one_row.append(GEMsort_clust_id[ch][idd]) \n",
    "\n",
    "GEMsort_all_id_one_row = np.array(np.unique(GEMsort_all_id_one_row))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging similar clusters coming from near channels: for every ch_near near channels\n",
    "\n",
    "ch_near = 30 #number of channels to be considered as near (depends on electrode characteristics)\n",
    "\n",
    "\n",
    "corr_thr1 = 0.5\n",
    "for ch in range(ch_near, 384 - ch_near): \n",
    "    if ch not in ch_ref:\n",
    "#     print(ch)\n",
    "        for i in range(-ch_near,ch_near):\n",
    "            if (np.array(GEMsort_clust_id[ch]).shape[0] > 0) & (np.array(GEMsort_clust_id[ch+i+1]).shape[0]) > 0: #it is not null\n",
    "                for p in range(np.array(GEMsort_clust_id[ch]).shape[0]):\n",
    "                    corr = []\n",
    "                    indexes = []\n",
    "                    for t in range(np.array(GEMsort_clust_id[ch+i+1]).shape[0]):\n",
    "                        ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "                        ave_nonmain = np.mean(GEMsort_cluster[ch+i+1][t],axis=0)\n",
    "                        indexes.append(p) #just to choose the highest corr\n",
    "                        corr.append(1 - spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "        #                 corr_max[j]=max((np.array(corr)))\n",
    "        #                 index_max[j] = np.argmax((np.array(corr)))\n",
    "                    corr_final = max((np.array(corr))) \n",
    "                    sj = np.argmax((np.array(corr))) \n",
    "\n",
    "                    if corr_final > corr_thr1:\n",
    "    #                     print('GEMsort_clust_id[ch+i+1][sj]', GEMsort_clust_id[ch+i+1][sj])\n",
    "                        GEMsort_clust_id[ch+i+1][sj] = GEMsort_clust_id[ch][p]\n",
    "#                     print('GEMsort_clust_id[ch+i+1][sj]', GEMsort_clust_id[ch+i+1][sj])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ch in range(382): \n",
    "#     print(ch)\n",
    "    if (np.array(GEMsort_clust_id[ch]).shape[0] > 0) & (np.array(GEMsort_clust_id[ch+1]).shape[0]) > 0: #it is not null\n",
    "    \n",
    "        for p in range(np.array(GEMsort_clust_id[ch]).shape[0]):\n",
    "            corr = []\n",
    "            indexes = []\n",
    "            for t in range(np.array(GEMsort_clust_id[ch+1]).shape[0]):\n",
    "                ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "                ave_nonmain = np.mean(GEMsort_cluster[ch+1][t],axis=0)\n",
    "                indexes.append(p) #to choose the highest corr\n",
    "                corr.append(1 - spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "                #corr_max[j] = max((np.array(corr)))\n",
    "                #index_max[j] = np.argmax((np.array(corr)))\n",
    "                #print('corr',corr)\n",
    "            corr_final = max((np.array(corr))) \n",
    "            sj = np.argmax((np.array(corr))) \n",
    "            #ss=index_max[sj] \n",
    "        \n",
    "            if corr_final > corr_thr1:\n",
    "                GEMsort_clust_id[ch+1][sj] = GEMsort_clust_id[ch][p]\n",
    "                \n",
    "       #for next channel ch+2\n",
    "            if (np.array(GEMsort_clust_id[ch+2]).shape[0]>0):\n",
    "                corr = []\n",
    "                indexes = []\n",
    "                for t in range(np.array(GEMsort_clust_id[ch+2]).shape[0]):\n",
    "                    ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "                    ave_nonmain = np.mean(GEMsort_cluster[ch+2][t],axis=0)\n",
    "                    indexes.append(p) \n",
    "                    corr.append(1 -spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "                    #corr_max[j]=max((np.array(corr)))\n",
    "                    #index_max[j] = np.argmax((np.array(corr)))\n",
    "                    #print('corr',corr)\n",
    "                corr_final = max((np.array(corr))) \n",
    "                sj = np.argmax((np.array(corr))) \n",
    "                #ss=index_max[sj]\n",
    "\n",
    "                if corr_final > corr_thr1:\n",
    "                    GEMsort_clust_id[ch+2][sj] = GEMsort_clust_id[ch][p]\n",
    "                    \n",
    "          #for next channel ch+3\n",
    "            if (np.array(GEMsort_clust_id[ch+3]).shape[0] > 0):\n",
    "                corr = []\n",
    "                indexes = []\n",
    "                for t in range(np.array(GEMsort_clust_id[ch+3]).shape[0]):\n",
    "                    ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "                    ave_nonmain = np.mean(GEMsort_cluster[ch+3][t],axis=0)\n",
    "                    indexes.append(p) #to choose the highest corr\n",
    "                    corr.append(1 - spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "                    #corr_max[j]=max((np.array(corr)))\n",
    "                    #index_max[j] = np.argmax((np.array(corr)))\n",
    "                    #print('corr',corr)\n",
    "                corr_final = max((np.array(corr))) \n",
    "                sj = np.argmax((np.array(corr)))\n",
    "\n",
    "                if corr_final > corr_thr1:\n",
    "                    GEMsort_clust_id[ch+3][sj] = GEMsort_clust_id[ch][p]\n",
    "                    \n",
    "#            #for next channel ch+4\n",
    "#             if (np.array(GEMsort_clust_id[ch+4]).shape[0] > 0):\n",
    "#                 corr = []\n",
    "#                 indexes = []\n",
    "#                 for t in range(np.array(GEMsort_clust_id[ch+4]).shape[0]):\n",
    "#                     ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "#                     ave_nonmain = np.mean(GEMsort_cluster[ch+4][t],axis=0)\n",
    "#                     indexes.append(p) #just to choose the highest corr\n",
    "#                     corr.append(1 - spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "#     #                 corr_max[j] = max((np.array(corr)))\n",
    "#     #                 index_max[j] = np.argmax((np.array(corr)))\n",
    "#                 print('corr',corr)\n",
    "#                 corr_final = max((np.array(corr))) \n",
    "#                 sj = np.argmax((np.array(corr))) \n",
    "#                 #ss = index_max[sj] \n",
    "\n",
    "#                 if corr_final > corr_thr1:\n",
    "#                     GEMsort_clust_id[ch+4][sj] = GEMsort_clust_id[ch][p]\n",
    "                    \n",
    "#             #for next channel ch+5\n",
    "#             if (np.array(GEMsort_clust_id[ch+5]).shape[0] > 0):\n",
    "#                 corr = []\n",
    "#                 indexes = []\n",
    "#                 for t in range(np.array(GEMsort_clust_id[ch+5]).shape[0]):\n",
    "#                     ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "#                     ave_nonmain = np.mean(GEMsort_cluster[ch+5][t],axis=0)\n",
    "#                     indexes.append(p) # to choose the highest corr\n",
    "#                     corr.append(1 - spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "#     #                 corr_max[j] = max((np.array(corr)))\n",
    "#     #                 index_max[j] = np.argmax((np.array(corr)))\n",
    "#                 print('corr',corr)\n",
    "#                 corr_final = max((np.array(corr))) \n",
    "#                 sj = np.argmax((np.array(corr))) \n",
    "#                 #ss = index_max[sj]\n",
    "\n",
    "#                 if corr_final > corr_thr1:\n",
    "#                     GEMsort_clust_id[ch+5][sj] = GEMsort_clust_id[ch][p] \n",
    "                    \n",
    "#             #for next channel ch+6\n",
    "#             if (np.array(GEMsort_clust_id[ch+6]).shape[0] > 0):\n",
    "#                 corr = []\n",
    "#                 indexes = []\n",
    "#                 for t in range(np.array(GEMsort_clust_id[ch+6]).shape[0]):\n",
    "#                     ave_main = np.mean(GEMsort_cluster[ch][p],axis=0)\n",
    "#                     ave_nonmain = np.mean(GEMsort_cluster[ch+6][t],axis=0)\n",
    "#                     indexes.append(p) #just to choose the highest corr\n",
    "#                     corr.append(1 -spatial.distance.cosine(ave_nonmain, ave_main))       \n",
    "#     #                 corr_max[j] = max((np.array(corr)))\n",
    "#     #                 index_max[j] = np.argmax((np.array(corr)))\n",
    "#                 print('corr',corr)\n",
    "#                 corr_final = max((np.array(corr))) \n",
    "#                 sj = np.argmax((np.array(corr))) \n",
    "#                 #ss = index_max[sj] \n",
    "\n",
    "#                 if corr_final > corr_thr1:\n",
    "#                     GEMsort_clust_id[ch+5][sj] = GEMsort_clust_id[ch][p]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the number of clusters after merging\n",
    "GEMsort_all_id_one_row = []\n",
    "for ch in range(384):\n",
    "    if i not in ch_ref:\n",
    "        if np.array(GEMsort_clust_id[ch]).shape[0] > 0: \n",
    "            for idd in range(np.array(GEMsort_clust_id[ch]).shape[0]): \n",
    "                GEMsort_all_id_one_row.append(GEMsort_clust_id[ch][idd]) #for the comparison matrix later only\n",
    "\n",
    "GEMsort_all_id_one_row = np.array(np.unique(GEMsort_all_id_one_row))    \n",
    "# GEMsort_all_id_one_row.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GEMsort_cluster       #spikes of all channels\n",
    "\n",
    "GEMsort_clust_id      #cluster id of detected groups\n",
    "\n",
    "GEMsort_ave_cluster   #the average waveforms of all clusters\n",
    "\n",
    "GEMsort_all_times     #all detected times of the clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
